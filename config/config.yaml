# Image Captioning Model Configuration File
# This file contains all hyperparameters and settings for training

# Data Configuration
data:
  # Paths to training data
  train_annotation_path: "data/raw/datasets/annotations_trainval2017/annotations/captions_train2017.json"
  train_image_path: "data/raw/datasets/train2017/train2017"
  
  # Paths to validation data
  val_annotation_path: "data/raw/datasets/annotations_trainval2017/annotations/captions_val2017.json"
  val_image_path: "data/raw/datasets/val2017/val2017"
  
  # Image preprocessing settings
  image_size: [256, 256]  # [height, width]
  
  # Caption settings
  max_caption_length: 22  # Maximum length of captions
  min_word_freq: 5  # Minimum frequency for a word to be in vocabulary
  oov_token: "<OOV>"  # Out of vocabulary token

# Model Architecture Configuration
model:
  # Embedding layer size
  embed_size: 100
  
  # LSTM hidden size
  hidden_size: 512
  
  # Number of LSTM layers
  num_layers: 2
  
  # Dropout rate (0.0 to 1.0)
  dropout: 0.3
  
  # Pretrained embeddings settings
  use_pretrained_embeddings: true
  glove_path: "data/raw/glove.6B.100d.txt"

  # image embedding dim
  feature_dim: 512

# Training Configuration
training:
  # Number of training epochs
  num_epochs: 10
  
  # Batch size for training
  batch_size: 32
  
  # Number of data loading workers
  num_workers: 1
  
  # Optimizer settings
  optimizer: "adam"  # Options: "adam", "sgd"
  learning_rate: 0.0001
  weight_decay: 0.0001
  momentum: 0.9  # Only used for SGD
  
  # Gradient clipping (0 to disable)
  grad_clip: 5.0
  
  # Device settings
  use_cuda: true  # Use GPU if available
  
  # Random seed for reproducibility
  seed: 42

  experiment_name: "2"
  
  # Checkpoint settings
  checkpoint_dir: "experiments/experiment_2/checkpoint"

# Logging Configuration
logging:
  log_dir: "experiments/logs"
  log_level: "INFO"
  tensorboard: true
  save_samples: true  # Save sample predictions during validation
  sample_frequency: 10  # Save samples every N epochs

